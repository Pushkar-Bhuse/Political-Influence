{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis-(SVC / TF-IDF).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPf59S8z3cfiOH0B5lehAj8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pushkar-Bhuse/Political-Influence/blob/master/SentimentAnalysis-(SVC/TF-IDF).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alm5a8hcKWwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin, BaseEstimator\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fF-1jLIHXjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vaSOWRQHbiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQVpftLeIQIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"1gJcmE0W1uFiHuhuivCjE1MA2hTZJuXNW\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('train.csv')        # replace the file name with your file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zag2srdbIlVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"1y3FJe_RN9m8kBK5jthChmRez21F5gx5H\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('test.csv')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juj04BneKFFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fdda9a45-46ea-4f49-dd8a-4a5debb1d2ad"
      },
      "source": [
        "train_data = pd.read_csv(\"train.csv\", encoding='ISO-8859-1')\n",
        "train_data.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ItemID</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ItemID  Sentiment                                      SentimentText\n",
              "0       1          0                       is so sad for my APL frie...\n",
              "1       2          0                     I missed the New Moon trail...\n",
              "2       3          1                            omg its already 7:30 :O\n",
              "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
              "4       5          0           i think mi bf is cheating on me!!!   ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXx4eJvSKlfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "953ddef1-59ef-489e-9360-03d93a1ed67c"
      },
      "source": [
        "#Checking Tweets\n",
        "rand_indexs = np.random.randint(1,len(train_data),10).tolist()\n",
        "train_data[\"SentimentText\"][rand_indexs]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26272    @adorableD yahhh dar, u missed the announcemen...\n",
              "80564    @artistjanebush Thanks! My head is bobbin'.  I...\n",
              "43973                                 @anisalovesu Right? \n",
              "83925    @CateP36  Thats awesome! I take it Twitter jus...\n",
              "85632    @audaciaray @debaucheddiva I tried to text 266...\n",
              "60006    @Belleslife Im spewing Poh got out she was my ...\n",
              "12943    *tired* researching publishers and proof readi...\n",
              "93334    @Contendo Perhaps I could be of assistance  We...\n",
              "45344    @aNorthernSoul That's a nice pic. Thx for shar...\n",
              "79989    @chamcircuit im going 2 try your comp but as i...\n",
              "Name: SentimentText, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUl0fttPK4Xa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "34178cea-2936-4c43-9996-f4f7a2b3b780"
      },
      "source": [
        "tweets_text = train_data.SentimentText.str.cat()\n",
        "emos = set(re.findall(r\" ([xX:;][-']?.) \",tweets_text))\n",
        "emos_count = []\n",
        "for emo in emos:\n",
        "    emos_count.append((tweets_text.count(emo), emo))\n",
        "sorted(emos_count,reverse=True)[:10]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(3281, ':/'),\n",
              " (2874, 'x '),\n",
              " (2626, ': '),\n",
              " (1339, 'x@'),\n",
              " (1214, 'xx'),\n",
              " (1162, 'xa'),\n",
              " (984, ';3'),\n",
              " (887, 'xp'),\n",
              " (842, 'xo'),\n",
              " (713, ';)')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NGELOz5LPOv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "af14a5a7-3523-4f37-e8ea-239e9816672a"
      },
      "source": [
        "HAPPY_EMO = r\" ([xX;:]-?[dD)]|:-?[\\)]|[;:][pP]) \"\n",
        "SAD_EMO = r\" (:'?[/|\\(]) \"\n",
        "print(\"Happy emoticons:\", set(re.findall(HAPPY_EMO, tweets_text)))\n",
        "print(\"Sad emoticons:\", set(re.findall(SAD_EMO, tweets_text)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Happy emoticons: {'xD', ':D', ':d', ':p', 'x)', ';-)', ';D', 'xd', ';)', ':-D', ';p', ';P', ';-D', ';d', 'XD'}\n",
            "Sad emoticons: {':|', ':/', \":'(\", ':('}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X42M8T8uNm6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "aefe16b8-2535-4283-e060-3d17cd194d7e"
      },
      "source": [
        "# nltk.download('punkt')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_X1xwXlMvtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def most_used_words(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    frequency_dist = nltk.FreqDist(tokens)\n",
        "    print(\"There is %d different words\" % len(set(tokens)))\n",
        "    return sorted(frequency_dist,key=frequency_dist.__getitem__, reverse=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRwwt1diNeJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "836b120b-9ca2-4d68-ecb7-fa685b091e5a"
      },
      "source": [
        "most_used_words(train_data.SentimentText.str.cat())[:10]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There is 134028 different words\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@', '!', '.', 'I', ',', 'to', 'the', 'you', '?', 'a']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIKY1bWVNjc5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a2c79b86-8884-4ccb-8404-823bc401a27b"
      },
      "source": [
        "# nltk.download(\"stopwords\")\n",
        "\n",
        "mw = most_used_words(train_data.SentimentText.str.cat())\n",
        "most_words = []\n",
        "for w in mw:\n",
        "    if len(most_words) == 1000:\n",
        "        break\n",
        "    if w in stopwords.words(\"english\"):\n",
        "        continue\n",
        "    else:\n",
        "        most_words.append(w)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "There is 134028 different words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwHK6UUFPdg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stem_tokenize(text):\n",
        "    stemmer = SnowballStemmer(\"english\")\n",
        "    stemmer = WordNetLemmatizer()\n",
        "    return [stemmer.lemmatize(token) for token in word_tokenize(text)]\n",
        "\n",
        "def lemmatize_tokenize(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(token) for token in word_tokenize(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4weXcqKQ0fb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "04f50857-47cb-43ee-ef01-5107460d259f"
      },
      "source": [
        "train_data['SentimentText'] = train_data['SentimentText'].str.replace(\"#\", \"\")\n",
        "train_data['SentimentText'] = train_data['SentimentText'].str.replace(r\"[-\\.\\n]\", \"\")\n",
        "# Removing HTML garbage\n",
        "train_data['SentimentText'] = train_data['SentimentText'].str.replace(r\"&\\w+;\", \"\")\n",
        "# Removing links\n",
        "train_data['SentimentText'] = train_data['SentimentText'].str.replace(r\"https?://\\S*\", \"\")\n",
        "# replace repeated letters with only two occurences\n",
        "# heeeelllloooo => heelloo\n",
        "train_data['SentimentText'] = train_data['SentimentText'].str.replace(r\"(.)\\1+\", r\"\\1\\1\")\n",
        "# mark emoticons as happy or sad\n",
        "train_data['SentimentText'] = train_data['SentimentText'].str.replace(HAPPY_EMO, \" happyemoticons \")\n",
        "train_data['SentimentText'] = train_data['SentimentText'].str.replace(SAD_EMO, \" sademoticons \")\n",
        "train_data['SentimentText'] = train_data['SentimentText'].str.lower()\n",
        "\n",
        "train_data.head(10)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ItemID</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my apl friend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>i missed the new moon trailer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 7:30 :o</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>omgaga im soo  im gunna cry i've been at thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>i think mi bf is cheating on me!!  t_t</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>or i just worry too much?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>juusst chillin!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>sunny again  work tomorrow  sademoticons  tv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>handed in my uniform today  i miss you already</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>hmm i wonder how she my number @)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ItemID  Sentiment                                      SentimentText\n",
              "0       1          0                        is so sad for my apl friend\n",
              "1       2          0                      i missed the new moon trailer\n",
              "2       3          1                            omg its already 7:30 :o\n",
              "3       4          0    omgaga im soo  im gunna cry i've been at thi...\n",
              "4       5          0             i think mi bf is cheating on me!!  t_t\n",
              "5       6          0                        or i just worry too much?  \n",
              "6       7          1                                   juusst chillin!!\n",
              "7       8          0    sunny again  work tomorrow  sademoticons  tv...\n",
              "8       9          1     handed in my uniform today  i miss you already\n",
              "9      10          1                  hmm i wonder how she my number @)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOfSsNB4SD2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Handling tags, In this case we remove all the tags\n",
        "train_data['SentimentText'] = train_data['SentimentText'].str.replace(r\"@[a-zA-Z0-9_]* \", \"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZqOtsQ2Sns3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiments = train_data['Sentiment']\n",
        "tweets = train_data['SentimentText']\n",
        "\n",
        "#using TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(tokenizer=lemmatize_tokenize, ngram_range=(1,2))\n",
        "\n",
        "clf = SVC(probability=True)\n",
        "\n",
        "grid_search_pipeline = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('SVC', clf)\n",
        "])\n",
        "\n",
        "params = [\n",
        "    {\n",
        "        'vectorizer__max_features': [1000, 2000, 5000, 10000, 20000, None],\n",
        "        'vectorizer__ngram_range': [(1,1), (1,2)],\n",
        "        'SVC__C': [0.1, 1, 10, 100, 1000],  \n",
        "        'SVC__gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
        "        'SVC__kernel': ['rbf', 'linear', 'poly']\n",
        "    },\n",
        "]\n",
        "\n",
        "grid_search = GridSearchCV(grid_search_pipeline, params, cv=5, scoring='f1')\n",
        "grid_search.fit(tweets, sentiments)\n",
        "print(grid_search.best_params_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-hfx6XETcgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d50b8f94-e81b-469d-97c1-f593fc1d9dab"
      },
      "source": [
        "#nltk.download('wordnet')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nUH-LkTTjJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}